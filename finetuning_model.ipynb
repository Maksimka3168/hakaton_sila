{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-Arb5CUZ23n"
   },
   "source": [
    "# Решение кейса от компании **\"СИЛА\"** **Автоматическая диспетчеризация заявок**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlcZCITBZz6M"
   },
   "source": [
    "В этом ноутбуке мы рассмотрим задачу классификации отказов оборудования на основе текстовых описаний. Мы будем использовать предобученную модель BERT для обработки текстовых данных и предсказывать точки отказа и типы оборудования. Также реализуем извлечение серийного номера из текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWVWaH3haFzY"
   },
   "source": [
    "## **Импорт необходимых библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxJpXK35Z16x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QV8iuWhaM1Y"
   },
   "source": [
    "## **Установка устройства для вычислений**\n",
    "\n",
    "Проверяем доступность GPU и устанавливаем соответствующее устройство для выполнения вычислений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ispXYPoYaO7-",
    "outputId": "9467a4a7-f541-475d-fc0e-5cd9ee0fec41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFmoNnsXbKj5"
   },
   "source": [
    "## **Задаём словарь для популярных слов**\n",
    "\n",
    "Создаём словарь, чтобы модель точно могла понимать классификацию типа продукции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4KYQCcQbRi3"
   },
   "outputs": [],
   "source": [
    "typo_dict = {\n",
    "    'ноутбку':'ноутбук', 'нобутук':'ноутбук', 'нотубук':'ноутбук', 'ноубтук':'ноутбук', 'ноутбу':'ноутбук', 'ноотбук':'ноутбук', 'наутбук':'ноутбук', 'нуотбук':'ноутбук', 'ноутьбук':'ноутбук', 'ноутбюк':'ноутбук', 'ноутбк':'ноутбук', 'нотбук':'ноутбук', 'нтубук':'ноутбук', 'нотуьбук':'ноутбук', 'ноубук':'ноутбук', 'нойтбук':'ноутбук', 'ноутбукк':'ноутбук', 'ноутбуук':'ноутбук', 'ноутубк':'ноутбук', 'ноутбукь':'ноутбук', 'нвотбук':'ноутбук', 'нюотбук':'ноутбук', 'оутбук':'ноутбук', 'ноытбук':'ноутбук', 'ноутюук':'ноутбук', 'нотубка':'ноутбук', 'нотубку':'ноутбук', 'нбоубук':'ноутбук', 'ноутубук':'ноутбук', 'нтуьбук':'ноутбук', 'нтбук':'ноутбук', 'нтобук':'ноутбук', 'ноубкук':'ноутбук', 'ноутубкк':'ноутбук', 'нботбук':'ноутбук', 'нотуб':'ноутбук', 'ноубтбук':'ноутбук', 'нтбк':'ноутбук', 'нобук':'ноутбук', 'нтубку':'ноутбук', 'нуотбк':'ноутбук', 'ноуьбук':'ноутбук', 'нотубка':'ноутбук', 'нотубк':'ноутбук', 'ноутбюук':'ноутбук', 'ноутуб':'ноутбук', 'ноутбкк':'ноутбук', 'нотбк':'ноутбук', 'нотубкка':'ноутбук', 'нобтбук':'ноутбук', 'нотюбук':'ноутбук', 'нтюбук':'ноутбук', 'нюьбук':'ноутбук', 'нотбкук':'ноутбук',\n",
    "\n",
    "    'свервер':'сервер', 'сревер':'сервер', 'серер':'сервер', 'сервеер':'сервер', 'серве':'сервер', 'сеервер':'сервер', 'сервр':'сервер', 'сервар':'сервер', 'сервир':'сервер', 'серевр':'сервер', 'серевер':'сервер', 'сервре':'сервер', 'серверь':'сервер', 'серверр':'сервер', 'сервере':'сервер', 'сервис':'сервер', 'севрер':'сервер', 'севвер':'сервер', 'сервыер':'сервер', 'сервери':'сервер', 'сревре':'сервер', 'срвер':'сервер', 'сервен':'сервер', 'срввер':'сервер', 'сервёер':'сервер', 'серввёр':'сервер', 'север':'сервер', 'севр':'сервер', 'северь':'сервер', 'сервйер':'сервер', 'сервср':'сервер', 'севвёр':'сервер', 'сервёр':'сервер', 'сррвер':'сервер', 'северр':'сервер', 'серрвер':'сервер', 'серррвер':'сервер', 'серввер':'сервер', 'сервирр':'сервер', 'сервквер':'сервер'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNHEkMOJaS6D"
   },
   "source": [
    "## **Определение вспомогательных функций**\n",
    "\n",
    "Здесь мы определяем несколько функций, которые помогут в обработке данных и оценке модели.\n",
    "\n",
    "* `extract_serial_number`: извлекает серийный номер из текста\n",
    "* `compare_serial_numbers`: сравнивает извлеченный и ожидаемый серийные номера.\n",
    "* `evaluate_serial_numbers`: оценивает точность извлечения серийных номеров.\n",
    "* `preprocess_text`: выполняет предварительную обработку текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LdAHjsPbU6w"
   },
   "outputs": [],
   "source": [
    "def extract_serial_number(text):\n",
    "    \"\"\"\n",
    "    Извлекает серийный номер из текста. Если серийный номер не найден, возвращает 'Уточнить'.\n",
    "\n",
    "    Параметры:\n",
    "    text (str): Входной текст, из которого нужно извлечь серийный номер.\n",
    "\n",
    "    Возвращает:\n",
    "    str: Извлеченный серийный номер или 'Уточнить'.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Нет серийного номера'\n",
    "\n",
    "    text = text.upper()\n",
    "\n",
    "    cyrillic_to_latin = {\n",
    "        ord('А'): 'A', ord('В'): 'B', ord('Е'): 'E', ord('К'): 'K',\n",
    "        ord('М'): 'M', ord('Н'): 'H', ord('О'): 'O', ord('Р'): 'R',\n",
    "        ord('С'): 'C', ord('Т'): 'T', ord('У'): 'Y', ord('Х'): 'X',\n",
    "        ord('Ц'): 'C', ord('Ч'): 'CH', ord('Ш'): 'SH', ord('Щ'): 'SCH',\n",
    "        ord('Ь'): '', ord('Ы'): 'Y', ord('Ъ'): '', ord('Э'): 'E',\n",
    "        ord('Ю'): 'YU', ord('Я'): 'YA',\n",
    "\n",
    "        ord('а'): 'A', ord('в'): 'B', ord('е'): 'E', ord('к'): 'K',\n",
    "        ord('м'): 'M', ord('н'): 'H', ord('о'): 'O', ord('р'): 'R',\n",
    "        ord('с'): 'C', ord('т'): 'T', ord('у'): 'Y', ord('х'): 'X',\n",
    "        ord('ц'): 'C', ord('ч'): 'CH', ord('ш'): 'SH', ord('щ'): 'SCH',\n",
    "        ord('ь'): '', ord('ы'): 'Y', ord('ъ'): '', ord('э'): 'E',\n",
    "        ord('ю'): 'YU', ord('я'): 'YA',\n",
    "    }\n",
    "\n",
    "    text = text.translate(cyrillic_to_latin)\n",
    "\n",
    "    pattern = r'\\b[A-Z]{1,4}\\d{6,}\\b'\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return 'Уточнить'\n",
    "\n",
    "def compare_serial_numbers(extracted, expected):\n",
    "    \"\"\"\n",
    "    Сравнивает извлеченный и ожидаемый серийные номера.\n",
    "\n",
    "    Параметры:\n",
    "    extracted (str): Извлеченный серийный номер.\n",
    "    expected (str): Ожидаемый серийный номер.\n",
    "\n",
    "    Возвращает:\n",
    "    bool: True, если серийные номера совпадают, иначе False.\n",
    "    \"\"\"\n",
    "    if expected == 'Нет серийного номера':\n",
    "        return extracted == 'Нет серийного номера'\n",
    "    else:\n",
    "        expected_serial = expected.upper().strip()\n",
    "        extracted_serial = extracted.upper().strip()\n",
    "        return expected_serial == extracted_serial\n",
    "\n",
    "def evaluate_serial_numbers(true_serials, extracted_serials):\n",
    "    \"\"\"\n",
    "    Оценивает точность извлечения серийных номеров.\n",
    "\n",
    "    Параметры:\n",
    "    true_serials (list): Список истинных серийных номеров.\n",
    "    extracted_serials (list): Список извлеченных серийных номеров.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Доля правильно извлеченных серийных номеров.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(true_serials)\n",
    "    for true_serial, extracted in zip(true_serials, extracted_serials):\n",
    "        if compare_serial_numbers(extracted, true_serial):\n",
    "            correct += 1\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Выполняет предварительную обработку текста:\n",
    "    - Удаляет специальные символы.\n",
    "    - Приводит текст к нижнему регистру.\n",
    "    - Удаляет лишние пробелы.\n",
    "\n",
    "    Параметры:\n",
    "    text (str): Исходный текст.\n",
    "\n",
    "    Возвращает:\n",
    "    str: Обработанный текст.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'_x000D_', ' ', str(text))\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "\n",
    "    # Заменяем опечатки\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        corrected_word = typo_dict.get(word, word)\n",
    "        corrected_words.append(corrected_word)\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GlmRbpbbYvN"
   },
   "source": [
    "## **Загрузка и подготовка данных**\n",
    "\n",
    "Загружаем датасет из CSV-файла и выполняем предварительную обработку данных для дальнейшего использования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-X-NK4wVbrJ6",
    "outputId": "a684c98e-69aa-4bfa-ebc2-b5ee80b8ebd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество загруженных строк: 10661\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'dataset/dataset.csv'\n",
    "data = pd.read_csv(\n",
    "    dataset_path,\n",
    "    sep=',',\n",
    "    encoding='utf-8',\n",
    "    on_bad_lines='skip',\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "print(f\"Количество загруженных строк: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y81cLNSffUN"
   },
   "source": [
    "## **Объединение столбцов 'Тема' и 'Описание'**\n",
    "\n",
    "Объединяем столбцы 'Тема' и 'Описание' в один текстовый столбец для удобства обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ygNhaegfnrZ"
   },
   "outputs": [],
   "source": [
    "# Объединяем столбцы 'Тема' и 'Описание' в один текстовый столбец\n",
    "data['text'] = data['Тема'].astype(str) + ' ' + data['Описание'].astype(str)\n",
    "data['text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00t6f2j-bssD"
   },
   "source": [
    "## **Обработка отсутствующих значений в 'Точке отказа'**\n",
    "\n",
    "Заполняем пропущенные значения в столбце 'Точка отказа' значением 'Нет точки отказа', если такое значение отсутствует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aspT-Gc6byK5"
   },
   "outputs": [],
   "source": [
    "# Обрабатываем отсутствующие значения в 'Точке отказа'\n",
    "if 'Нет точки отказа' not in data['Точка отказа'].unique():\n",
    "    data['Точка отказа'] = data['Точка отказа'].fillna('Нет точки отказа')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz0iyrFSb0D7"
   },
   "source": [
    "## **Кодирование целевых переменных**\n",
    "\n",
    "Используем `LabelEncoder` для преобразования категориальных признаков в числовые значения, необходимые для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8DnyikNcP3O"
   },
   "outputs": [],
   "source": [
    "# Кодируем целевые переменные\n",
    "label_encoder_point = LabelEncoder()\n",
    "label_encoder_type = LabelEncoder()\n",
    "\n",
    "data['Точка отказа'] = label_encoder_point.fit_transform(data['Точка отказа'])\n",
    "data['Тип оборудования'] = label_encoder_type.fit_transform(data['Тип оборудования'])\n",
    "\n",
    "point_classes = label_encoder_point.classes_\n",
    "type_classes = label_encoder_type.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxOAHNtlcURN"
   },
   "source": [
    "## **Инициализация токенизатора**\n",
    "\n",
    "Используем предобученный токенизатор `DeepPavlov/rubert-base-cased` для преобразования текстовых данных в числовые тензоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Cooi0I2cibs",
    "outputId": "c11aafd1-1a48-4b49-9a99-aacd835d8cd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-YPfWyUcjdg"
   },
   "source": [
    "## **Создание класса `CustomDataset`**\n",
    "\n",
    "Определяем класс `CustomDataset`, который будет использоваться для загрузки данных в модель в формате, совместимом с PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zv0kydOcqlP"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Кастомный датасет для загрузки текстовых данных и соответствующих меток.\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, targets_point, targets_type, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets_point = targets_point\n",
    "        self.targets_type = targets_type\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Возвращает общее количество примеров в датасете.\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        Возвращает один пример из датасета.\n",
    "\n",
    "        Параметры:\n",
    "        item (int): Индекс примера.\n",
    "\n",
    "        Возвращает:\n",
    "        dict: Словарь с входными данными и метками.\n",
    "        \"\"\"\n",
    "        text = str(self.texts[item])\n",
    "        target_point = self.targets_point[item]\n",
    "        target_type = self.targets_type[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'target_point': torch.tensor(target_point, dtype=torch.long),\n",
    "            'target_type': torch.tensor(target_type, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSU0kH3bcrrZ"
   },
   "source": [
    "## **Определение модели классификации**\n",
    "\n",
    "Создаем класс `ClassificationModel`, который включает в себя предобученную модель BERT и дополнительные слои для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44xEqc7dcv6t"
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Модель для классификации точки отказа и типа оборудования на основе выходов BERT.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes_point, n_classes_type):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out_point = nn.Linear(self.bert.config.hidden_size, n_classes_point)\n",
    "        self.out_type = nn.Linear(self.bert.config.hidden_size, n_classes_type)\n",
    "\n",
    "        # Размораживаем все параметры BERT для обучения\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "\n",
    "        Параметры:\n",
    "        input_ids (torch.Tensor): Идентификаторы входных токенов.\n",
    "        attention_mask (torch.Tensor): Маска внимания.\n",
    "\n",
    "        Возвращает:\n",
    "        tuple: Логиты для точки отказа и типа оборудования.\n",
    "        \"\"\"\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.drop(pooled_output)\n",
    "        point_logits = self.out_point(output)\n",
    "        type_logits = self.out_type(output)\n",
    "        return point_logits, type_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEJ4n3amcxMw"
   },
   "source": [
    "## **Разделение данных на обучающую и валидационную выборки**\n",
    "\n",
    "Используем функцию `train_test_split` для разделения данных на обучающую и валидационную выборки в соотношении 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhk9Ay9jc0iz"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_point, y_val_point, y_train_type, y_val_type = train_test_split(\n",
    "    data['text'],\n",
    "    data['Точка отказа'],\n",
    "    data['Тип оборудования'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO7JJbbec1pU"
   },
   "source": [
    "## **Подготовка `DataLoader` для обучения и валидации**\n",
    "\n",
    "Создаем загрузчики данных (`DataLoader`) для обучения и валидации, что позволит эффективно передавать данные в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snM2a-ICc8Oo",
    "outputId": "883f4ece-31a6-42de-8fda-de3e2272ef15"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Создаем датасет и загрузчик для обучения\n",
    "train_dataset = CustomDataset(\n",
    "    X_train.values,\n",
    "    y_train_point.values,\n",
    "    y_train_type.values,\n",
    "    tokenizer,\n",
    "    MAX_LEN\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "# Создаем датасет и загрузчик для валидации\n",
    "val_dataset = CustomDataset(\n",
    "    X_val.values,\n",
    "    y_val_point.values,\n",
    "    y_val_type.values,\n",
    "    tokenizer,\n",
    "    MAX_LEN\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True if torch.cuda.is_available() else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvwEoxaNdKlq"
   },
   "source": [
    "## **Определение функций обучения и оценки модели**\n",
    "\n",
    "Создаем функции `train_epoch` и `eval_model`, которые будут использоваться для обучения модели и оценки ее качества на валидационном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elGq5wkEdP-F"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scaler):\n",
    "    \"\"\"\n",
    "    Обучает модель на одной эпохе.\n",
    "\n",
    "    Параметры:\n",
    "    model (nn.Module): Обучаемая модель.\n",
    "    data_loader (DataLoader): Загрузчик данных для обучения.\n",
    "    loss_fn (nn.Module): Функция потерь.\n",
    "    optimizer (torch.optim.Optimizer): Оптимизатор.\n",
    "    device (torch.device): Устройство для вычислений.\n",
    "    scaler (GradScaler): Скалер для AMP.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Среднее значение функции потерь за эпоху.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = d['attention_mask'].to(device, non_blocking=True)\n",
    "        target_point = d['target_point'].to(device, non_blocking=True)\n",
    "        target_type = d['target_type'].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs_point, outputs_type = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            loss_point = loss_fn(outputs_point, target_point)\n",
    "            loss_type = loss_fn(outputs_type, target_type)\n",
    "            loss = loss_point + loss_type\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Оценивает модель на валидационном наборе.\n",
    "\n",
    "    Параметры:\n",
    "    model (nn.Module): Обученная модель.\n",
    "    data_loader (DataLoader): Загрузчик данных для валидации.\n",
    "    loss_fn (nn.Module): Функция потерь.\n",
    "    device (torch.device): Устройство для вычислений.\n",
    "\n",
    "    Возвращает:\n",
    "    tuple: Среднее значение функции потерь, предсказания и истинные метки.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    predictions_point = []\n",
    "    predictions_type = []\n",
    "    real_point = []\n",
    "    real_type = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = d['attention_mask'].to(device, non_blocking=True)\n",
    "            target_point = d['target_point'].to(device, non_blocking=True)\n",
    "            target_type = d['target_type'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                outputs_point, outputs_type = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "                loss_point = loss_fn(outputs_point, target_point)\n",
    "                loss_type = loss_fn(outputs_type, target_type)\n",
    "                loss = loss_point + loss_type\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            _, preds_point_batch = torch.max(outputs_point, dim=1)\n",
    "            _, preds_type_batch = torch.max(outputs_type, dim=1)\n",
    "\n",
    "            predictions_point.extend(preds_point_batch.cpu().numpy())\n",
    "            predictions_type.extend(preds_type_batch.cpu().numpy())\n",
    "            real_point.extend(target_point.cpu().numpy())\n",
    "            real_type.extend(target_type.cpu().numpy())\n",
    "\n",
    "    return np.mean(losses), predictions_point, predictions_type, real_point, real_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlyt1Qh9dQw6"
   },
   "source": [
    "## **Функция предсказания для нового текста**\n",
    "\n",
    "Определяем функцию `predict`, которая принимает на вход новый текст и возвращает предсказания модели вместе с извлеченным серийным номером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dKtqFR5dUg2"
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, label_encoder_point, label_encoder_type, device, max_len=512):\n",
    "    \"\"\"\n",
    "    Делает предсказание для нового текста.\n",
    "\n",
    "    Параметры:\n",
    "    text (str): Входной текст.\n",
    "    model (nn.Module): Обученная модель.\n",
    "    tokenizer (AutoTokenizer): Токенизатор.\n",
    "    label_encoder_point (LabelEncoder): Кодировщик меток для точки отказа.\n",
    "    label_encoder_type (LabelEncoder): Кодировщик меток для типа оборудования.\n",
    "    device (torch.device): Устройство для вычислений.\n",
    "    max_len (int): Максимальная длина последовательности.\n",
    "\n",
    "    Возвращает:\n",
    "    tuple: Предсказанные метки для точки отказа и типа оборудования, а также извлеченный серийный номер.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        processed_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device, non_blocking=True)\n",
    "    attention_mask = encoding['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs_point, outputs_type = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "    _, preds_point = torch.max(outputs_point, dim=1)\n",
    "    _, preds_type = torch.max(outputs_type, dim=1)\n",
    "\n",
    "    point_label = label_encoder_point.inverse_transform(preds_point.cpu().numpy())[0]\n",
    "    type_label = label_encoder_type.inverse_transform(preds_type.cpu().numpy())[0]\n",
    "\n",
    "    serial_number = extract_serial_number(text)\n",
    "\n",
    "    return point_label, type_label, serial_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRaDFPQ6dVU-"
   },
   "source": [
    "## **Инициализация и обучение модели**\n",
    "\n",
    "Создаем экземпляр модели, определяем оптимизатор и функцию потерь. Затем запускаем процесс обучения модели на протяжении нескольких эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tg738l6ldY9I",
    "outputId": "f10e144c-ca63-45f2-d9f8-c16397aac6d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-e4f407656798>:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6069507066127473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5886828052370172\n",
      "F1 Score Точка отказа: 0.8781012581350554\n",
      "F1 Score Тип оборудования: 0.9972293983035933\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9584435521462162\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5236653564250575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.4302425128326081\n",
      "F1 Score Точка отказа: 0.8779736530542179\n",
      "F1 Score Тип оборудования: 0.9983379141014769\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9587705223852315\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3480498824367481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.32486540811103687\n",
      "F1 Score Точка отказа: 0.902040692006507\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.966977580378081\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25627729916467074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.29698395650637777\n",
      "F1 Score Точка отказа: 0.9121281135552519\n",
      "F1 Score Тип оборудования: 0.9983379141014769\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.970155342552243\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20808296162733989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.29860010063439085\n",
      "F1 Score Точка отказа: 0.9085400256999222\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9691440249425528\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.155879245873178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3043949455022812\n",
      "F1 Score Точка отказа: 0.9180089543443891\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9723003344907083\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1216369130673398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3037992734135243\n",
      "F1 Score Точка отказа: 0.9234010396702897\n",
      "F1 Score Тип оборудования: 0.998338395158454\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9739131449429146\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10258932374170528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3318051536355102\n",
      "F1 Score Точка отказа: 0.9096488306015563\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9695136265764308\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0904211798039949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3212786698550509\n",
      "F1 Score Точка отказа: 0.9213119599825605\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9734013363700988\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-ffa3729ce326>:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07331951405951935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ffa3729ce326>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.35019769852882937\n",
      "F1 Score Точка отказа: 0.9158359536282206\n",
      "F1 Score Тип оборудования: 0.9988920491277361\n",
      "Accuracy для серийного номера: 1.0\n",
      "Средняя метрика: 0.9715760009186521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classes_point = len(point_classes)\n",
    "n_classes_type = len(type_classes)\n",
    "\n",
    "model = ClassificationModel(n_classes_point, n_classes_type)\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Используем {torch.cuda.device_count()} GPU\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "scaler = GradScaler()\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scaler\n",
    "    )\n",
    "    print(f'Train loss: {train_loss}')\n",
    "\n",
    "    val_loss, preds_point, preds_type, real_point, real_type = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device\n",
    "    )\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "\n",
    "    f1_point = f1_score(real_point, preds_point, average='weighted')\n",
    "    f1_type = f1_score(real_type, preds_type, average='weighted')\n",
    "    print(f'F1 Score Точка отказа: {f1_point}')\n",
    "    print(f'F1 Score Тип оборудования: {f1_type}')\n",
    "\n",
    "    val_texts = X_val.values\n",
    "    val_true_serials = data.loc[X_val.index, 'Серийный номер'].values\n",
    "    val_extracted_serials = [extract_serial_number(text) for text in val_texts]\n",
    "    serial_accuracy = evaluate_serial_numbers(val_true_serials, val_extracted_serials)\n",
    "    print(f'Accuracy для серийного номера: {serial_accuracy}')\n",
    "\n",
    "    average_metric = (f1_point + f1_type + serial_accuracy) / 3\n",
    "    print(f'Средняя метрика: {average_metric}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntQjav_ddZQ1"
   },
   "source": [
    "## **Сохранение обученной модели**\n",
    "\n",
    "После обучения сохраняем модель для последующего использования, используя `torch.jit` для создания скриптованной версии модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRuVmVpqdduf"
   },
   "outputs": [],
   "source": [
    "# Определяем путь для сохранения модели\n",
    "model_save_dir = os.path.dirname(dataset_path)\n",
    "model_save_path = os.path.join(model_save_dir, 'model.pt')\n",
    "\n",
    "try:\n",
    "    # Подготовка примерного входа для трассировки\n",
    "    example_input_ids = torch.randint(0, tokenizer.vocab_size, (1, MAX_LEN)).to(device)\n",
    "    example_attention_mask = torch.ones((1, MAX_LEN), dtype=torch.long).to(device)\n",
    "\n",
    "    # Трассировка модели\n",
    "    scripted_model = torch.jit.trace(model, (example_input_ids, example_attention_mask))\n",
    "\n",
    "    # Сохранение трассированной модели\n",
    "    torch.jit.save(scripted_model, model_save_path)\n",
    "\n",
    "    print(f\"Модель сохранена по пути: {model_save_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Не удалось сохранить модель с помощью torch.jit: {e}\")\n",
    "    # Альтернативно, сохраняем state_dict модели\n",
    "    model_state_dict_path = os.path.join(model_save_dir, 'model_state_dict.pth')\n",
    "    torch.save(model.state_dict(), model_state_dict_path)\n",
    "    print(f\"Сохранена state_dict модели по пути: {model_state_dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6V8YvrKVrJV"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(label_encoder_point, 'label_encoder_point.joblib')\n",
    "joblib.dump(label_encoder_type, 'label_encoder_type.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXzs-qdZdfwc"
   },
   "source": [
    "## **Пример использования обученной модели**\n",
    "\n",
    "Показываем, как можно использовать сохраненную модель для предсказания на новом тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMQPQmlNdjUs"
   },
   "outputs": [],
   "source": [
    "# Пример использования модели\n",
    "new_text = \"\"\"\n",
    "Привет. Пришел конец моему ноутбуку ABCD123456.\n",
    "\"\"\"\n",
    "\n",
    "point_label, type_label, serial_number = predict(\n",
    "    new_text,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    label_encoder_point,\n",
    "    label_encoder_type,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(f'Точка отказа: {point_label}')\n",
    "print(f'Тип оборудования: {type_label}')\n",
    "print(f'Серийный номер: {serial_number}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
